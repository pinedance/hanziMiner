{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KMcorpus\n",
    "\n",
    "class KMcorpus:\n",
    "    \n",
    "    PC = \"[,\\.!\\?！＇，ㆍ．／：；？｀、。·‥…¨〃∼´～˝\\(\\)\\{\\}\\[\\]（）［］｛｝‘’“”〔〕〈〉《》「」『』【】]\"\n",
    "    \n",
    "    def __init__( self, text, comments_header=\"#\", doc_sep=\"\\r?\\n\\r?\\n\" ):\n",
    "        self.text = text\n",
    "        self.doc_sep = doc_sep\n",
    "        self.comments_header = comments_header\n",
    "        self.docs = []\n",
    "        \n",
    "    def remove_comments( self ):\n",
    "        pattern = \"{}.*?$\".format( self.comments_header )\n",
    "        regex = re.compile( pattern, re.MULTILINE|re.DOTALL )\n",
    "        self.text = re.sub( regex, \"\", self.text ).strip()\n",
    "        return self\n",
    "        \n",
    "    def remove_punctuation( self ):  \n",
    "        regex_PC = re.compile( self.PC )\n",
    "        self.text = re.sub( regex_PC , \" \", self.text ).strip()\n",
    "        return self\n",
    "    \n",
    "    def remove_chrs( self, chr_types=[\"Korean\", \"Alphabet\", \"Numbers\"] ):\n",
    "        if \"Korean\" in chr_types:\n",
    "            self.text = re.sub( re.compile(\"[가-힣]\"), \"\", self.text )\n",
    "        if \"Alphabet\" in chr_types:\n",
    "            self.text = re.sub( re.compile(\"[a-zA-Z]\"), \"\", self.text )\n",
    "        if \"Numbers\" in chr_types:\n",
    "            self.text = re.sub( re.compile(\"[\\d]+?\"), \"\", self.text )\n",
    "        self.text = self.text.strip()\n",
    "        return self\n",
    "    \n",
    "    def merge_spaces( self ):\n",
    "        self.text = re.sub( re.compile(\"[ \\t]+?\"), \" \", self.text )\n",
    "        self.text = re.sub( re.compile(\"^[ \\t]+?\", re.MULTILINE|re.DOTALL), \"\", self.text ).strip()\n",
    "        return self\n",
    "        \n",
    "    def text2docs(self):\n",
    "        docs = re.split( re.compile( self.doc_sep ), self.text )\n",
    "        self.docs = [ doc.strip().split() for doc in docs ]\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def merge_duplications(self, dict_path=\"dicts/duplications.dic\" ):\n",
    "        return self.merge_chrs( dict_path ) \n",
    "    \n",
    "    def merge_variants(self, dict_path=\"dicts/variants.dic\" ):\n",
    "        return self.merge_chrs( dict_path ) \n",
    "    \n",
    "    def merge_chrs(self, dict_path ):\n",
    "        dic = open(dict_path, 'r', encoding='utf-8').readlines()\n",
    "        for pair in dic:\n",
    "            a, b = pair.split(\"\\t\")\n",
    "            self.text = self.text.replace(a, b)\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Segment\n",
    "\n",
    "class TokenExtractor:\n",
    "    \n",
    "    def __init__( self, corpus, min_freq = 5 ):\n",
    "        self.corpus = corpus\n",
    "        self.min_freq = min_freq\n",
    "        self.token_counter = Counter()\n",
    "        self.unigram_counter = Counter( self.corpus.text )\n",
    "        self.bigram_counter = Counter()\n",
    "        self.score = defaultdict()\n",
    "        \n",
    "    def train( self, method=\"allgram\", min_window=2, max_window=8 ):\n",
    "        \n",
    "        self.min_window = min_window\n",
    "        \n",
    "        if method == \"allgram\" :\n",
    "            for doc in self.corpus.docs:\n",
    "                for phrase in doc:\n",
    "                    particles = self.__class__.allgram( phrase, min_window, max_window )\n",
    "                    self.token_counter.update( Counter( particles ) )\n",
    "                    \n",
    "                    bigrams = self.__class__.ngram( phrase, n=2 )\n",
    "                    self.bigram_counter.update( Counter( bigrams ) )\n",
    "\n",
    "        self.token_counter = Counter( {x : self.token_counter[x] for x in self.token_counter if self.token_counter[x] >= self.min_freq } )\n",
    "        return self\n",
    "        \n",
    "    def cohesion_score( self, word ):\n",
    "        word_len = len( word )\n",
    "        if (not word) or ( word_len < self.min_window ):\n",
    "            return 0\n",
    "        \n",
    "        first_chr_freq = self.unigram_counter[ word[0] ]\n",
    "        last_chr_freq = self.unigram_counter[ word[-1] ]\n",
    "        whole_word_freq = self.token_counter[ word ]\n",
    "        \n",
    "        cohesion_l = 0 if whole_word_freq == 0 else math.pow( ( whole_word_freq / first_chr_freq ), (1 / (word_len - 1)) )\n",
    "        cohesion_r = 0 if whole_word_freq == 0 else math.pow( ( whole_word_freq / last_chr_freq ), (1 / (word_len - 1)) )\n",
    "        return ( cohesion_l, cohesion_r,  cohesion_l * cohesion_r, (cohesion_l + cohesion_r)/2 )\n",
    "\n",
    "    def extract( self ):\n",
    "        for x in self.token_counter:\n",
    "            _score = namedtuple('Score', ['freq', 'cohesion_l', 'cohesion_r', 'cohesion', 'cohesion_s'])\n",
    "            _score.freq = self.token_counter[x]\n",
    "            _score.cohesion_l, _score.cohesion_r, _score.cohesion, _score.cohesion_s  = self.cohesion_score( x )\n",
    "            self.score[x] = _score\n",
    "        return self.score\n",
    "    \n",
    "    @staticmethod\n",
    "    def ngram( text, n):\n",
    "        return [ text[i:i+n] for i in range( 0, len(text) - n + 1 )  ]\n",
    "\n",
    "    def allgram( text, min_window=2, max_window=8 ):\n",
    "        len_txt = len(text)\n",
    "        mx_wd = len_txt if ( len_txt < max_window ) else max_window\n",
    "        rst = []\n",
    "        for i in range(min_window, mx_wd + 1):\n",
    "            rst += TokenExtractor.ngram(text, i)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Segmenter:\n",
    "    \n",
    "    def __init__( self, token_with_score, target_score=\"cohesion_s\", score_cutoff=0.02):\n",
    "        self.score_list = [ ( tk, getattr( sc, target_score ) ) for tk, sc in token_with_score.items() if getattr( sc, target_score ) >= score_cutoff  ]\n",
    "        self.score = dict( self.score_list )\n",
    "        self.tokens = self.score.keys()\n",
    "        self.target_text = \"\"\n",
    "        \n",
    "    def load( self, text, min_window=2, max_window=8 ):\n",
    "        _token_candis = set( TokenExtractor.allgram(text, min_window, max_window) )\n",
    "        token_candis_with_score = [ ( it, self.score[it] ) for it in _token_candis if it in self.tokens ]\n",
    "        self.token_candis = sorted( token_candis_with_score, key=lambda x: (-x[1], -len(x[0] )  ) )\n",
    "        self.target_text = text\n",
    "        return self\n",
    "    \n",
    "    def segment( self, segment_marker=\"$\" ):\n",
    "        target_text = self.target_text + \"\"\n",
    "        self.segment_marker = segment_marker\n",
    "        for i, candi in enumerate( self.token_candis ):\n",
    "            marker = \"{0}{1}{0}\".format( self.segment_marker, i )\n",
    "            target_text = marker.join( target_text.split( candi[0] ) )\n",
    "        \n",
    "        self.text_segment_marked = target_text\n",
    "        return self\n",
    "    \n",
    "    def show( self, verbose=False, sep=\"%\"):\n",
    "        target_text = self.text_segment_marked + \"\"\n",
    "        for i, candi in enumerate( self.token_candis ):\n",
    "            marker = \"{0}{1}{0}\".format( self.segment_marker, i )\n",
    "            seg = \"【{0}/{1:01.3f}】\".format( candi[0], candi[1] ) if verbose else \"【{}】\".format( candi[0] )\n",
    "            target_text = target_text.replace(marker, seg )\n",
    "        self.text_segmented = target_text    \n",
    "        return target_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ending\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "text = open(\"_tmp/_dummy_corpus.txt\", 'r', encoding=\"utf-8\").read()\n",
    "corpus = KMcorpus(text, comments_header=\"//\")\n",
    "corpus.merge_duplications().merge_variants().remove_comments().remove_punctuation().remove_chrs().merge_spaces().text2docs()\n",
    "\n",
    "tmp = open(\"_tmp/_dummy_corpus_clean.txt\", 'w', encoding=\"utf-8\")\n",
    "pp = pprint.PrettyPrinter(indent=4, stream=tmp)\n",
    "pp.pprint( corpus.docs )\n",
    "\n",
    "te = TokenExtractor( corpus )\n",
    "te.train().extract()\n",
    "print(\"train ending\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('茱萸', 0.947980397980398), ('川芎', 0.7391782540875262), ('右爲末', 0.5921452228091995), ('爲末', 0.4845754162786111), ('人參', 0.4609669379041367), ('山茱萸', 0.43029153176491475), ('眩暈', 0.3594959749782085), ('甘菊', 0.32764004542013625), ('每二錢', 0.32498633756266126), ('右爲', 0.28247710679528576), ('各五錢', 0.2818964624190051), ('二錢', 0.2591218108911663), ('一兩', 0.25458261843574165), ('本事', 0.21540697948819604), ('山茱', 0.19401709401709402), ('調下', 0.1829016762105842), ('酒調下', 0.18200296579184727), ('各五', 0.17176678034247622), ('五錢', 0.15146704420881457), ('山藥', 0.1411460010735373), ('每二', 0.12820259481350757), ('酒調', 0.11455354381164418), ('茯神', 0.09468202147760157), ('治風', 0.040685718028607584)]\n",
      "【治風】證【眩暈】. 山【茱萸】肉 【一兩】, 【山藥】ㆍ【甘菊】ㆍ【人參】ㆍ【川芎】ㆍ【茯神】 【各五錢】. 【右爲末】, 【每二錢】, 酒【調下】. 《【本事】》\n",
      "\n",
      "\n",
      "[('思慮', 0.37985573423333996), ('小便', 0.34370002284669865), ('不能', 0.23154676774135768), ('以手摩', 0.20549052773867427), ('君子', 0.20006366756215352), ('令人', 0.15978098924150275), ('喜怒', 0.13790439401255433), ('眞人養', 0.12844228102842686), ('飽食', 0.12413869102463244), ('不得', 0.10656281136151773), ('手摩', 0.09914469766686515), ('鼻中', 0.0956072581015382), ('辟惡', 0.08265640259665652), ('令人長', 0.07965663828743372), ('終始', 0.06645735217163788), ('秋冬', 0.06601112950515586), ('眞人', 0.06330750337077967), ('施泄', 0.06134466308884914), ('大醉', 0.05717085696529729), ('不能成', 0.0551228336137649), ('病不能', 0.05154326549999177), ('百病不', 0.047062864053452766), ('諸疾', 0.04692550907246172), ('一日', 0.04672290176203971), ('去鼻中', 0.043748457459997336), ('正氣', 0.04319288871029714), ('最爲', 0.043191391338686325), ('百病', 0.04208094824163558), ('百步', 0.040406593743297484), ('以手', 0.037272456607431975), ('春夏', 0.036666008266112764), ('飮酒', 0.035761316695906556), ('左脚', 0.03567499607103568), ('傷於', 0.02995997116222793), ('頭髮', 0.02952565154534443), ('養生', 0.026711953251407405), ('終無', 0.0251198944572213), ('長壽', 0.023879275105600218), ('壽不', 0.021712501260494427), ('飢則', 0.020973840649832157)]\n",
      "【眞人養】生銘曰人欲勞於形【百病】【不能】成【飮酒】勿【大醉】【諸疾】自不生食了行【百步】數【以手摩】肚寅丑日剪甲【頭髮】梳百度飽卽立【小便】【飢則】坐漩尿行處勿當風居止無小隙常夜濯足臥【飽食】【終無】益【思慮】最傷神【喜怒】最傷氣每去【鼻中】毛常習不唾地平明欲起時下床先【左脚】【一日】無災殃去邪兼【辟惡】如能七星步【令人】【長壽】樂酸味【傷於】筋苦味【傷於】骨甘卽不益肉辛多敗【正氣】鹹多促人壽【不得】偏耽嗜【春夏】少【施泄】【秋冬】固陽事獨臥是守眞愼靜【最爲】貴錢財生有分知足將爲利强知是大患少慾【終無】累神靜自常安修道宜【終始】書之屋壁中將以傳【君子】\n",
      "\n",
      "\n",
      "[('本草', 0.7069522318802581), ('爲末', 0.4845754162786111), ('空心', 0.45582745250540424), ('每二錢', 0.32498633756266126), ('延年', 0.3128081804219546), ('二錢', 0.2591218108911663), ('溫酒調', 0.23454963369767629), ('溫酒調服', 0.2026563640930386), ('曝乾', 0.19062825860271115), ('搗爲末', 0.17988951374197087), ('酒浸', 0.16950973035774797), ('溫酒', 0.1555491985535435), ('酒調服', 0.1347444086564743), ('每二', 0.12820259481350757), ('酒調', 0.11455354381164418), ('日二次', 0.11394092411255823), ('明目', 0.09461135992295899), ('調服', 0.09233982284147826), ('久服', 0.07663039971610155), ('空心溫', 0.07126868931987293), ('輕身', 0.05929174788823911), ('搗爲', 0.04985934993832848), ('一日', 0.04672290176203971), ('調服一', 0.038890322894064605), ('一日二', 0.03053500085576195), ('二次', 0.02891772994851275), ('如此', 0.02816834755966033), ('九次', 0.028120354416301223), ('日二', 0.02432988219104949)]\n",
      "【久服】【明目】【輕身】【延年】【酒浸】【曝乾】蒸之【如此】【九次】搗【爲末】【每二錢】【空心】【溫酒調】服一【日二次】【本草】\n",
      "\n",
      "\n",
      "[('糊和丸梧', 0.7467296219107697), ('糊和丸梧子大', 0.7054552911230046), ('梧子大', 0.6719513827537683), ('糊和丸梧子', 0.6527048712604954), ('和丸梧子大', 0.5777609419135269), ('和丸梧', 0.568757045905546), ('梧子', 0.5637724091417586), ('糊和丸', 0.5597765490444586), ('蒼朮', 0.5361711830220117), ('丸梧', 0.5348296914827233), ('穿山甲', 0.5327977211413666), ('茴香', 0.5234758234057463), ('得效', 0.5060074629960312), ('丸梧子大', 0.5035977951760437), ('酒糊和丸梧子大', 0.4940723948083216), ('爲末', 0.4845754162786111), ('和丸梧子', 0.4828736913285891), ('糊和', 0.4614668722527788), ('酒糊和丸梧', 0.4528528583962436), ('酒糊和丸梧子', 0.4294628833249773), ('丸梧子', 0.35842938841222893), ('穿山', 0.2844597174494082), ('焙乾', 0.2685031213681653), ('一兩', 0.25458261843574165), ('酒糊和丸', 0.25223066043345865), ('手足', 0.25029507529507533), ('下五十丸', 0.2368325622880555), ('半生半炒', 0.23680119442288572), ('疼痛', 0.218827386828374), ('各二兩', 0.2184607618859977), ('擂爛', 0.21374790853318462), ('酒下五十丸', 0.21313877970924971), ('和丸', 0.21096518675040282), ('十丸', 0.2009527777692362), ('五十丸', 0.19461410255408212), ('溫酒下五', 0.18682915816815282), ('一兩半', 0.17113584759305758), ('子大', 0.16691239076523184), ('酒糊和', 0.15604241567062965), ('溫酒', 0.1555491985535435), ('溫酒下', 0.14587517687496354), ('半生半', 0.14471492105848432), ('酒下五十', 0.138080384831519), ('二兩', 0.13590255953412025), ('下五十', 0.1327377146792663), ('風寒濕', 0.1311226849401452), ('各二', 0.1211916880742232), ('四兩', 0.11710110210574157), ('生薑四兩', 0.11334959970090228), ('生薑', 0.11234608119995457), ('生半炒', 0.1096936531198363), ('折傷', 0.10612258023023988), ('山甲', 0.10474853268569116), ('酒下五', 0.0974334375286981), ('宿焙乾', 0.0933195859460049), ('骨碎補', 0.09268728443862245), ('酒糊', 0.08676666250512761), ('無妨', 0.08667622430623409), ('五十', 0.07441411358068087), ('骨碎', 0.07003389109538054), ('兩半', 0.06458574969558352), ('碎補', 0.05428786084057208), ('風寒', 0.05201341876609218), ('下五', 0.04780549538771967), ('草烏', 0.04579480956388067), ('生薑四', 0.04577017598268486), ('寒濕', 0.04565340433036588), ('薑四兩', 0.04531853613490551), ('治折傷', 0.04431691528283848), ('酒下', 0.03926860870675175), ('爲末酒', 0.033408447546014), ('宿焙', 0.03232702772739052), ('爲風寒', 0.032077975080713486), ('治折', 0.024462661546782873), ('右將', 0.022303962321132267), ('半生', 0.02124583817174589), ('桑灰', 0.02057716114713825)]\n",
      "治【折傷】後爲【風寒濕】所侵【手足】【疼痛】生【蒼朮】破古紙【半生半炒】【骨碎補】【穿山甲】【桑灰】炒爲珠生【草烏】【各二兩】【茴香】【一兩】半【右將】【草烏】剉如麥大同連皮【生薑】【四兩】【擂爛】淹兩宿【焙乾】同前藥【爲末】酒【糊和丸梧】【子大】【溫酒】【下五十丸】少麻【無妨】【得效】\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sg = Segmenter( te.score, target_score='cohesion' )\n",
    "sgl = Segmenter( te.score, target_score='cohesion_l' )\n",
    "sgr = Segmenter( te.score, target_score='cohesion_r' )\n",
    "sgs = Segmenter( te.score, target_score='cohesion_s' )\n",
    "\n",
    "\n",
    "docs = [\n",
    "    \"治風證眩暈. 山茱萸肉 一兩, 山藥ㆍ甘菊ㆍ人參ㆍ川芎ㆍ茯神 各五錢. 右爲末, 每二錢, 酒調下. 《本事》\",\n",
    "    \"眞人養生銘曰人欲勞於形百病不能成飮酒勿大醉諸疾自不生食了行百步數以手摩肚寅丑日剪甲頭髮梳百度飽卽立小便飢則坐漩尿行處勿當風居止無小隙常夜濯足臥飽食終無益思慮最傷神喜怒最傷氣每去鼻中毛常習不唾地平明欲起時下床先左脚一日無災殃去邪兼辟惡如能七星步令人長壽樂酸味傷於筋苦味傷於骨甘卽不益肉辛多敗正氣鹹多促人壽不得偏耽嗜春夏少施泄秋冬固陽事獨臥是守眞愼靜最爲貴錢財生有分知足將爲利强知是大患少慾終無累神靜自常安修道宜終始書之屋壁中將以傳君子\",\n",
    "    \"久服明目輕身延年酒浸曝乾蒸之如此九次搗爲末每二錢空心溫酒調服一日二次本草\",\n",
    "    \"治折傷後爲風寒濕所侵手足疼痛生蒼朮破古紙半生半炒骨碎補穿山甲桑灰炒爲珠生草烏各二兩茴香一兩半右將草烏剉如麥大同連皮生薑四兩擂爛淹兩宿焙乾同前藥爲末酒糊和丸梧子大溫酒下五十丸少麻無妨得效\"\n",
    "]\n",
    "\n",
    "for sn in docs:\n",
    "    #sg.load( sn ).segment()\n",
    "    #sgl.load( sn ).segment()\n",
    "    #sgr.load( sn ).segment()\n",
    "    sgs.load( sn ).segment()\n",
    "    print( sgs.token_candis )\n",
    "    #print( sg.target_text )\n",
    "    #print( sg.show() )\n",
    "    #print( sgl.show() )\n",
    "    #print( sgr.show() )\n",
    "    print( sgs.show() )\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83666002653407556"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power( 0.7, 1/2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending\n"
     ]
    }
   ],
   "source": [
    "rst = sorted( te.score.items(), key=lambda it: -1* ( it[1].cohesion_r * it[1].cohesion_l ) )\n",
    "tmp2 = open(\"_tmp/_dummy_corpus_score.txt\", 'w', encoding=\"utf-8\")\n",
    "pp = pprint.PrettyPrinter(indent=4, stream=tmp2)\n",
    "pp.pprint( [ ( r[0], r[1].freq , r[1].cohesion_r, r[1].cohesion_l ) for r in rst ] )\n",
    "\n",
    "print(\"ending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.unigram_counter.get(\"枸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'i': 17, 'h': 5, 'w': 4, 'u': 3, 'e': 2, 'r': 2, 'q': 2, ' ': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(\"huihihu ihuihi\") \n",
    "d = Counter(\"werwwqweqriiiiiiiiiiii\")\n",
    "c.update(d)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "97 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"c\" in {'a':1, 'b':2}.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict( [('a', 1), ('b', 2)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
